{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "\tmu, sigma = args\n",
    "\tbatch = K.shape(mu)[0]\n",
    "\tdim = K.int_shape(mu)[1]\n",
    "\teps = K.random_normal(shape=(batch, dim))\n",
    "\treturn mu + K.exp(sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_reconstruction_loss(true, pred):\n",
    "\t# Reconstruction loss\n",
    "\treconstruction_loss = binary_crossentropy(\n",
    "\t    K.flatten(true), K.flatten(pred)) * img_width * img_height\n",
    "\t# KL divergence loss\n",
    "\tkl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "\tkl_loss = K.sum(kl_loss, axis=-1)\n",
    "\tkl_loss *= -0.5\n",
    "\t# Total loss = 50% rec + 50% KL divergence loss\n",
    "\treturn K.mean(reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mse(x, vae):\n",
    "    pred = vae.predict(x, batch_size = batch_size)\n",
    "    sq = np.square(pred)\n",
    "    mean = np.mean(sq, (1,2,3))\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histrogram(x_train, x_test, anomaly_x_test):\n",
    "    vae = load_model(\n",
    "    'C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_with_idcard\\\\vae.h5', compile = False)\n",
    "    vae.compile(optimizer = 'adam', loss = kl_reconstruction_loss)\n",
    "\n",
    "    # calc error\n",
    "    fig, ax1 = plt.subplots(1,1, figsize = (8,8))\n",
    "    ax1.hist(model_mse(x_train, vae), alpha = 1.0, label = 'Training data', normed = True)\n",
    "    ax1.hist(model_mse(x_test, vae), alpha = 0.5, label = 'Testing data', normed = True)\n",
    "    ax1.hist(model_mse(anomaly_x_test, vae), alpha = 0.5, label = 'Anomaly data', normed = True)\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('Reconstruction Error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_comparison(x_test, anomaly_x_test):\n",
    "    # load model\n",
    "    vae = load_model(\n",
    "        'C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_with_idcard\\\\vae.h5', compile = False)\n",
    "    vae.compile(optimizer = 'adam', loss = kl_reconstruction_loss)\n",
    "\n",
    "    # reconstruction\n",
    "    fig, m_axs = plt.subplots(5,4, figsize=(20, 10))\n",
    "    [c_ax.axis('off') for c_ax in m_axs.ravel()]\n",
    "    for i, (axa_in, axa_vae, axt_in, axt_vae) in enumerate(m_axs):\n",
    "        axa_in.imshow(np.squeeze(anomaly_x_test[i]))\n",
    "        axa_in.set_title('Anomaly In')\n",
    "        axa_vae.imshow(vae.predict(anomaly_x_test[i:i+1])[0,:,:,0])\n",
    "        axa_vae.set_title('Anomaly/Reconstructed')\n",
    "        axt_in.imshow(np.squeeze(x_test[i]))\n",
    "        axt_in.set_title('Test In')\n",
    "        axt_vae.imshow(vae.predict(x_test[i:i+1])[0,:,:,0])\n",
    "        axt_vae.set_title('Test Reconstructed')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_latent_space(encoder, data):\n",
    "\tinput_data, target_data = data\n",
    "\tmu, _, _ = encoder.predict(input_data, batch_size = batch_size)\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tplt.scatter(mu[:, 0], mu[:, 1], c=target_data)\n",
    "\tplt.xlabel('z - dim 1')\n",
    "\tplt.ylabel('z - dim 2')\n",
    "\tplt.colorbar()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_outliers_colored(target_data):\n",
    "    cols=[]\n",
    "    for val in target_data:\n",
    "        if val == 1:\n",
    "            cols.append('red')\n",
    "        elif val == 7:\n",
    "            cols.append('blue')\n",
    "        else:\n",
    "            cols.append('green')\n",
    "\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_decoded(encoder, decoder, data):\n",
    "\tnum_samples = 15\n",
    "\tfigure = np.zeros(\n",
    "\t    (img_width * num_samples, img_height * num_samples, num_channels))\n",
    "\tgrid_x = np.linspace(-4, 4, num_samples)\n",
    "\tgrid_y = np.linspace(-4, 4, num_samples)[::-1]\n",
    "\tfor i, yi in enumerate(grid_y):\n",
    "\t\tfor j, xi in enumerate(grid_x):\n",
    "\t\t\tz_sample = np.array([[xi, yi]])\n",
    "\t\t\tx_decoded = decoder.predict(z_sample)\n",
    "\t\t\tdigit = x_decoded[0].reshape(img_width, img_height, num_channels)\n",
    "\t\t\tfigure[i * img_width: (i + 1) * img_width,\n",
    "\t\t\t\t\tj * img_height: (j + 1) * img_height] = digit\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tstart_range = img_width // 2\n",
    "\tend_range = num_samples * img_width + start_range + 1\n",
    "\tpixel_range = np.arange(start_range, end_range, img_width)\n",
    "\tsample_range_x = np.round(grid_x, 1)\n",
    "\tsample_range_y = np.round(grid_y, 1)\n",
    "\tplt.xticks(pixel_range, sample_range_x)\n",
    "\tplt.yticks(pixel_range, sample_range_y)\n",
    "\tplt.xlabel('z - dim 1')\n",
    "\tplt.ylabel('z - dim 2')\n",
    "\t# matplotlib.pyplot.imshow() needs a 2D array, or a 3D array with the third dimension being of shape 3 or 4!\n",
    "\t# So reshape if necessary\n",
    "\tfig_shape = np.shape(figure)\n",
    "\tif fig_shape[2] == 1:\n",
    "\t\tfigure = figure.reshape((fig_shape[0], fig_shape[1]))\n",
    "\t# Show image\n",
    "\tplt.imshow(figure)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAndPrepareImages(path) :\n",
    "    print('data prep begins')\n",
    "    img_array = []\n",
    "    for filename in os.listdir(path):\n",
    "        temp = cv2.imread(path + filename)\n",
    "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "        temp = cv2.resize(temp, (800, 600))\n",
    "        img_array.append(temp)\n",
    "\n",
    "    img_array = np.array(img_array, dtype=\"uint8\")\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config // hyperparameter\n",
    "img_width, img_height = 800, 600\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "latent_dim = 2\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    train_datagen = ImageDataGenerator( \n",
    "    rescale = 1. / 255, \n",
    "    shear_range = 0.2, \n",
    "    zoom_range = [0.5,1.0], \n",
    "    horizontal_flip = True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode=\"nearest\")\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(800, 600),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='input',\n",
    "        shuffle=True)\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(800, 600),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='input',\n",
    "        shuffle=True)\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    i = Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    en = Conv2D(filters=num_channels, kernel_size=2, padding='same', activation='relu')(i)\n",
    "    en = BatchNormalization()(en)\n",
    "    \n",
    "    en = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(en)\n",
    "    en = BatchNormalization()(en)\n",
    "    \n",
    "    en = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(en)\n",
    "    en = BatchNormalization()(en)\n",
    "\n",
    "    en = Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(en)\n",
    "    en_n = BatchNormalization()(en)\n",
    "    \n",
    "    en = Flatten()(en_n)\n",
    "    \n",
    "    en = Dense(128, activation='relu')(en)\n",
    "    en = BatchNormalization()(en)\n",
    "    \n",
    "    mu = Dense(latent_dim, name='latent_mu')(en)\n",
    "    sigma = Dense(latent_dim, name='latent_sigma')(en)\n",
    "\n",
    "    # get conv shape\n",
    "    conv_shape = K.int_shape(en_n)\n",
    "\n",
    "    # Use reparameterization trick to ensure correct gradient\n",
    "    z = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])\n",
    "\n",
    "    # Instantiate encoder\n",
    "    encoder = Model(i, [mu, sigma, z], name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    # decoder\n",
    "    de_i = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "\n",
    "    de = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(de_i)\n",
    "    de = BatchNormalization()(de)\n",
    "    \n",
    "    de = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(de)\n",
    "    \n",
    "    de = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(de)\n",
    "    de = BatchNormalization()(de)\n",
    "    \n",
    "    de = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(de)\n",
    "    de = BatchNormalization()(de)\n",
    "    \n",
    "    de = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(de)\n",
    "    de = BatchNormalization()(de)\n",
    "    \n",
    "    de = Conv2DTranspose(filters=num_channels, kernel_size=3, activation='sigmoid', padding='same', name='decoder_output')(de)\n",
    "\n",
    "    # Instantiate decoder\n",
    "    decoder = Model(de_i, de, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    # VAE\n",
    "    vae_outputs = decoder(encoder(i)[2])\n",
    "    vae = Model(i, vae_outputs, name='vae')\n",
    "    vae.summary()\n",
    "    \n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_and_train(encoder, decoder, vae):\n",
    "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
    "\n",
    "    # Train autoencoder\n",
    "    logdir = 'C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_idcard_color\\\\tmp\\\\vae_' + datetime.now().strftime(\"%H_%M\")\n",
    "\n",
    "    vae.fit(x_train, x_train, \n",
    "            epochs = epochs, \n",
    "            batch_size = batch_size, \n",
    "            validation_split = validation_split,\n",
    "            callbacks=[TensorBoard(log_dir='C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_idcard_color\\\\tmp\\\\vae_idcard800x600', histogram_freq=1)])\n",
    "\n",
    "    vae.save('C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_idcard_color\\\\vae.h5')\n",
    "\n",
    "    encoder.save('C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_idcard_color\\\\encoder.h5')\n",
    "\n",
    "    decoder.save('C:\\\\Users\\\\tim.reicheneder\\\\Desktop\\\\Bachelorthesis\\\\impl_final\\\\vae_idcard_color\\\\decoder.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-df3e8cefc6b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-8c2bd40039d9>\u001b[0m in \u001b[0;36mdefine_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'encoder_input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "encoder, decoder, vae = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
